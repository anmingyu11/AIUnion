{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多项式模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当特征是离散的时候，使用多项式模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# 预处理\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = load_breast_cancer()\n",
    "    return data.data,data.target\n",
    "\n",
    "def load_data_split():\n",
    "    X,y = load_data()\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def standardize(X_):\n",
    "    X_ = StandardScaler().fit_transform(X_)\n",
    "    return X_\n",
    "\n",
    "def load_data_split_standarize():\n",
    "    X_train,X_test,y_train,y_test = load_data_split()\n",
    "    return standardize(X_train),standardize(X_test),y_train,y_test\n",
    "\n",
    "def load_data_standarize_discret():\n",
    "    X_train,X_test,y_train,y_test = load_data_split_standarize()\n",
    "    kd = KBinsDiscretizer(encode='ordinal').fit(X_train)\n",
    "    X_train = kd.transform(X_train)\n",
    "    X_test = kd.transform(X_test)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB_amy:\n",
    "    '''\n",
    "    Naive Bayes classifier for multinomial models\n",
    "    The multinomial Naive Bayes classifier is suitable for classification with\n",
    "    discrete features\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, optional (default=1.0)\n",
    "            Setting alpha = 0 for no smoothing\n",
    "            Setting 0 < alpha < 1 is called Lidstone smoothing\n",
    "            Setting alpha = 1 is called Laplace smoothing \n",
    "    fit_prior : boolean\n",
    "            Whether to learn class prior probabilities or not.\n",
    "            If false, a uniform prior will be used.\n",
    "    class_prior : \n",
    "            array-like, size (n_classes,)\n",
    "            Prior probabilities of the classes. If specified the priors are not\n",
    "            adjusted according to the data.\n",
    "            类的先验概率\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self\n",
    "        #, alpha = 1.0\n",
    "        #, fit_prior = True\n",
    "        #, class_prior = None\n",
    "    ):\n",
    "        #self.alpha = alpha\n",
    "        #self.fit_prior = fit_prior\n",
    "        self.class_prior_ = None # class_prior\n",
    "        self.classes_ = None\n",
    "        self.conditional_prob_ = None\n",
    "\n",
    "    def _calculate_feature_prob(\n",
    "        self\n",
    "        , X_features_i\n",
    "        , feature_uniq\n",
    "    ):\n",
    "        '''\n",
    "        计算对应特征的条件概率\n",
    "        '''\n",
    "        # 样本总数 \n",
    "        n = len(X_features_i)\n",
    "        # 特征数\n",
    "        feature_n = len(feature_uniq)\n",
    "        # 存在于该集中特征的每个值的个数\n",
    "        feature_X_i_uniq ,feature_X_i_counts = np.unique(X_features_i ,return_counts=True)\n",
    "        # 初始化所有特征值的条件概率\n",
    "        feature_prob = {}\n",
    "        # 计算所有特征值的条件概率\n",
    "        for uniq in feature_uniq:\n",
    "            f_uniq_cnt = feature_X_i_counts[feature_X_i_uniq == uniq]\n",
    "            f_uniq_cnt = f_uniq_cnt[0] if len(f_uniq_cnt) > 0 else 0\n",
    "            prob = (f_uniq_cnt + 1.) / (n + feature_n)\n",
    "            feature_prob[uniq] = prob\n",
    "        return feature_prob\n",
    "        \n",
    "    def fit(\n",
    "        self\n",
    "        , X\n",
    "        , y\n",
    "    ):\n",
    "        n = len(y)\n",
    "        # 类别\n",
    "        self.classes_, classes_counts = np.unique(y,return_counts=True)\n",
    "        # 计算类的先验概率: P(y=ck)\n",
    "        self.class_prior_ = classes_counts / (n + len(self.classes_))\n",
    "        # 计算条件概率: P( xj | y = ck )\n",
    "        self.conditional_prob_ = {}  # like { c0:{ x0:{ value0:0.2, value1:0.8 }, x1:{} }, c1:{...} }\n",
    "        for c in self.classes_:\n",
    "            self.conditional_prob_[c] = {}\n",
    "            for i in range(X.shape[1]):  # for each feature\n",
    "                features = X[:, i] # 取特征i\n",
    "                feature_uniq = np.unique(features) # 取所有特征的值\n",
    "                X_features_i = features[y==c] # 取在c标签下的特征值\n",
    "                self.conditional_prob_[c][i] = self._calculate_feature_prob(\n",
    "                    X_features_i\n",
    "                    , feature_uniq\n",
    "                ) # 计算条件概率\n",
    "        return self\n",
    "\n",
    "    def predict_single(\n",
    "        self\n",
    "        , x):\n",
    "        max_p = 0.0\n",
    "        max_k = 0\n",
    "        class_prior_map = dict(zip(self.classes_,self.class_prior_))            \n",
    "        for k in class_prior_map.keys():\n",
    "            # 类的先验概率\n",
    "            c_p = class_prior_map[k]\n",
    "            for f_i in self.conditional_prob_.keys():\n",
    "                # 对应类k的条件概率\n",
    "                c_p =c_p * self.conditional_prob_[k][f_i][x[f_i]]\n",
    "            if(c_p > max_p):\n",
    "                max_k = k\n",
    "                max_p = c_p\n",
    "        \n",
    "        return max_k\n",
    "    \n",
    "    def predict(\n",
    "        self\n",
    "        , X\n",
    "    ):\n",
    "        y = np.empty(len(X))\n",
    "        for i,x in enumerate(X):\n",
    "            y[i] = self.predict_single(x)\n",
    "        return y\n",
    "    \n",
    "    def score(\n",
    "        self\n",
    "        ,X\n",
    "        ,y\n",
    "    ):\n",
    "        return np.sum(y==self.predict(X))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my score :  0.8951048951048951\n",
      "sklearn score : 0.7832167832167832\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = load_data_standarize_discret()\n",
    "mnb = MultinomialNB_amy().fit(X_train,y_train)\n",
    "mnb.predict(X_test)\n",
    "print('my score : ' , mnb.score(X_test,y_test))#应该没错\n",
    "#mnb.conditional_prob_\n",
    "skmnb=MultinomialNB().fit(X_train,y_train)\n",
    "print('sklearn score :' ,skmnb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk score :  0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = load_data_split_standarize()\n",
    "skgnb = GaussianNB().fit(X_train,y_train)\n",
    "print('sk score : ' , skgnb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB_amy():\n",
    "    def __init__(\n",
    "        self):\n",
    "        self.classes_prob_map_ = None\n",
    "        self.feature_std_mean_ = None\n",
    "      \n",
    "    def fit(\n",
    "        self\n",
    "        , X\n",
    "        , y):\n",
    "        # 样本数\n",
    "        n = len(y)\n",
    "        # 特征数\n",
    "        features_n = X.shape[1]\n",
    "        # 类的先验概率\n",
    "        class_uniq,class_cnts = np.unique(y,return_counts=True)\n",
    "        class_prob = class_cnts / n + len(class_uniq)\n",
    "        self.classes_prob_map_ = dict(zip(class_uniq,class_prob))\n",
    "        # 计算每个类对应特征的方差和均值\n",
    "        feature_std_mean = {}\n",
    "        # 所有的类别\n",
    "        for c in self.classes_prob_map_.keys():\n",
    "            f = {}\n",
    "            # 对每个特征计算均值方差\n",
    "            for i in range(X.shape[1]):\n",
    "                f[i] = {}\n",
    "                X_feature_i = X[: ,i]\n",
    "                X_c_feature_i = X_feature_i[y==c]\n",
    "                # c类第i个特征的均值方差\n",
    "                f[i]['mean'] = np.mean(X_c_feature_i)\n",
    "                f[i]['std'] = np.std(X_c_feature_i)\n",
    "            feature_std_mean[c] = f\n",
    "        self.feature_std_mean_ =feature_std_mean\n",
    "        return self\n",
    "         \n",
    "    def predict_single(\n",
    "        self\n",
    "        , x\n",
    "    ):\n",
    "        max_p = 0.0\n",
    "        max_c = 0\n",
    "        for c in self.classes_prob_map_.keys():\n",
    "            c_p = self.classes_prob_map_[c] \n",
    "            for i in range(len(x)):\n",
    "                mean = self.feature_std_mean_[c][i]['mean']\n",
    "                std = self.feature_std_mean_[c][i]['std']\n",
    "                c_p *= (1. / (np.sqrt(2 * np.pi) * std)) * np.exp( (-(x[i] - mean)**2) / (2 * (std ** 2)))\n",
    "            if(c_p > max_p):\n",
    "                max_c = c\n",
    "                max_p = c_p\n",
    "        return max_c\n",
    "    \n",
    "    def predict(\n",
    "        self\n",
    "        ,X\n",
    "    ):\n",
    "        y = np.empty(len(X))\n",
    "        for i,x in enumerate(X):\n",
    "            y[i] = self.predict_single(x)\n",
    "        return y\n",
    "    \n",
    "    def score(\n",
    "        self\n",
    "        ,X\n",
    "        ,y\n",
    "    ):\n",
    "        return np.sum(y==self.predict(X))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk score :  0.9300699300699301\n",
      "my score :  0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = load_data_split_standarize()\n",
    "skgnb = GaussianNB().fit(X_train,y_train)\n",
    "print('sk score : ' , skgnb.score(X_test,y_test))\n",
    "amygnb = GaussianNB_amy().fit(X_train,y_train)\n",
    "print('my score : ' , amygnb.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
