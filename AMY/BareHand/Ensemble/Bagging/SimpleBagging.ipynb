{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    digits = load_digits()\n",
    "    return digits.data,digits.target\n",
    "X,y = load_data()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "lor = DecisionTreeClassifier(max_depth=5,splitter='random').fit(X_train,y_train)\n",
    "lor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 64)\n",
      "(172,)\n",
      "(172,)\n"
     ]
    }
   ],
   "source": [
    "# 自助采样法\n",
    "def bs_test(X,y,m):\n",
    "    '''\n",
    "    bootstrap m次\n",
    "    '''\n",
    "    lens = len(y)\n",
    "    args = np.arange(0,lens,1)\n",
    "    # 放回抽样\n",
    "    samp_args = np.random.choice(args, m, True)\n",
    "    uniq_args = np.unique(samp_args) \n",
    "    return X[uniq_args],y[uniq_args],uniq_args\n",
    "    \n",
    "X_samp,y_samp,args = bs_test(X,y, len(y)//10)\n",
    "print(X_samp.shape)\n",
    "print(y_samp.shape)\n",
    "uniq ,cs = np.unique(args,return_counts=True)\n",
    "print(uniq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 200\n",
      "bag : 118\n",
      "oob : 0.41\n"
     ]
    }
   ],
   "source": [
    "# 算下oob,放回抽样\n",
    "n = 200\n",
    "\n",
    "# 样本集D 包含n个样本\n",
    "X_bs = X.copy()[:n]\n",
    "y_bs = y.copy()[:n]\n",
    "\n",
    "# 每次从样本集中D有放回的挑选1\n",
    "_, _, args = bs_test(X_bs,y_bs,1)\n",
    "\n",
    "# 重复执行n次\n",
    "for i in range(n - 1):\n",
    "    _, _, args_new = bs_test(X_bs,y_bs,1)\n",
    "    args = np.concatenate((args,args_new))\n",
    "    args = np.unique(args)\n",
    "\n",
    "# 得到样本子集D'\n",
    "oob_score = (n - args.shape[0]) / n\n",
    "\n",
    "# 样本数量\n",
    "print('m:',  n)\n",
    "# D'中的样本数量\n",
    "print('bag :',args.shape[0])\n",
    "# 袋外数据占比\n",
    "print('oob :',oob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boosstrap产生的数据集改变了初始数据的分布,这会引入估计偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sampling(X,y):\n",
    "    n = len(y)\n",
    "    args = np.arange(0,n,1)\n",
    "    # 放回抽样\n",
    "    samp_args = np.random.choice(args, n, True)\n",
    "    uniq_args = np.unique(samp_args) \n",
    "    return X[uniq_args],y[uniq_args],uniq_args\n",
    "\n",
    "# 试一试这样能否达到boosttrap的效果\n",
    "#oob_score = []\n",
    "#for _ in range(1000):\n",
    "#    _,_,samples = bootstrap_sampling(X,y)\n",
    "#    oob_score.append(1 - samples.shape[0] / y.shape[0])\n",
    "#np.mean(oob_score)# 约等于0.368,正确."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们采样出T个含m个样本的采样集,然后基于每个采样集训练处一个基学习器,再将这些基学习器进行结合.这就是Bagging的基本流程,Bagging通常对分类任务使用简单投票法,对回归任务使用简单平均法."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my test score :  0.9244444444444444\n",
      "sklearn bagging test score :  0.9155555555555556\n",
      "----------------------------------------------------------------------------------------------------\n",
      "my oob score:  0.8663697104677061\n",
      "sklearn bagging oob score 0.8057874234835838\n"
     ]
    }
   ],
   "source": [
    "class SimpleBagging:\n",
    "    \n",
    "    def __init__(\n",
    "        self\n",
    "        #,base_estimator\n",
    "        ,T = 30\n",
    "    ):\n",
    "        '''\n",
    "        @params T 循环的次数\n",
    "        @params 基分类器\n",
    "        @params X_ 训练数据\n",
    "        @params y_ 训练数据对应的标签\n",
    "        @params es_inbag_sample_args 每个基分类器对应的袋内索引\n",
    "        @params es_oobag_sample_args 每个基分类器对应的袋外索引\n",
    "        '''\n",
    "        self.T_ = T\n",
    "        # self.base_estimator_ = base_estimator\n",
    "        self.estimators_ = None\n",
    "        self.X_ = None\n",
    "        self.y_ = None\n",
    "        self.es_inbag_sample_args_ = None\n",
    "        self.es_oobag_sample_args_ = None\n",
    "\n",
    "        \n",
    "    def bootstrap_sampling(self,X,y):\n",
    "        n = len(y)\n",
    "        args = np.arange(0,n,1)\n",
    "        # 放回抽样\n",
    "        samp_args = np.random.choice(args, n, True)\n",
    "        uniq_args = np.unique(samp_args) \n",
    "        return X[uniq_args] ,y[uniq_args] ,uniq_args\n",
    "\n",
    "    def oob_sample_args(self,n,inb_sample_args):\n",
    "        args = np.arange(0 ,n ,1)\n",
    "        args[inb_sample_args] = -1\n",
    "        return args[ args >= 0 ]\n",
    "        \n",
    "    def fit(self ,X ,y):\n",
    "        # 初始化成员变量\n",
    "        n = len(y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.estimators_ = []\n",
    "        self.es_inbag_sample_args_ = []\n",
    "        self.es_oobag_sample_args_ = []\n",
    "        for i in range(self.T_):\n",
    "            # bootstrap采样\n",
    "            X_sample,y_sample,sample_args = self.bootstrap_sampling(X,y)\n",
    "            # print(sample_args.shape)\n",
    "            # 用采样数据训练数据\n",
    "            rnd_seed = np.random.randint(2**32 - 1)\n",
    "            clf = DecisionTreeClassifier(\n",
    "                max_depth = 5\n",
    "                , splitter='random'\n",
    "                , random_state=rnd_seed\n",
    "            ).fit(X_sample,y_sample)\n",
    "            # 更新成员变量\n",
    "            self.es_inbag_sample_args_.append(sample_args)\n",
    "            self.es_oobag_sample_args_.append(self.oob_sample_args(n, sample_args))\n",
    "            self.estimators_.append(clf)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        n = len(X_test)\n",
    "        y_p_set = np.zeros((self.T_,n),dtype=np.int32)\n",
    "        # For vote\n",
    "        for i , est in enumerate(self.estimators_):\n",
    "            yp = est.predict(X_test)\n",
    "            y_p_set[i]=yp\n",
    "        # 初始化预测结果\n",
    "        y_res = np.zeros(n, dtype=np.int32)\n",
    "        for i in range(n):\n",
    "            # 对每个样本各个预测器的投票结果\n",
    "            uniqs, uniq_cnts = np.unique(y_p_set[:,i], return_counts=True)\n",
    "            # 获取投票数量最大的索引\n",
    "            cnt_argmax = np.argmax(uniq_cnts)\n",
    "            #print('uniqs : ',uniqs, 'cnts : ',uniq_cnts,'argmax:',cnt_argmax)\n",
    "            y_res[i] = uniqs[cnt_argmax]\n",
    "        return y_res\n",
    "    \n",
    "    def __oob_predict(self):\n",
    "        # 仅考虑未使用x的分类器进行预测.\n",
    "        \n",
    "        # 投票的稀疏矩阵,行对应m个样本,列对应投票结果\n",
    "        y_res = []\n",
    "        # 用于预测的袋外数据\n",
    "        y_args = []\n",
    "        for i , x in enumerate(self.X_):\n",
    "            # 第i个样本的投票结果\n",
    "            y_i = []\n",
    "            # 遍历 T个基分类器\n",
    "            for t in range(self.T_):\n",
    "                # 第t个分类器的袋内数据索引.\n",
    "                es_inbag_args = self.es_inbag_sample_args_[t]\n",
    "                # 判断当前数据x是否参与了分类器t的训练.\n",
    "                if np.any(es_inbag_args == i):\n",
    "                    # 如果已经参与就终结循环,遍历后面的分类器.\n",
    "                    continue\n",
    "                # 当前分类没有用到当前数据x = X[i],用当前分类器来预测数据x.\n",
    "                y_p = self.estimators_[t].predict(x.reshape(1,-1))\n",
    "                # 记录投票结果\n",
    "                y_i.append(y_p.ravel()[0])\n",
    "            # 没有任何分类器没用到当前数据\n",
    "            if len(y_i) == 0:\n",
    "                continue\n",
    "            y_res.append(y_i)\n",
    "            y_args.append(i)\n",
    "        n = len(y_args)\n",
    "        y_final_p = np.full(n, -1)\n",
    "        \n",
    "        for i in range(n):\n",
    "            # 对每个样本各个预测器的投票结果\n",
    "            uniqs, uniq_cnts = np.unique(np.array(y_res[i]), return_counts=True)\n",
    "            # 获取投票数量最大的索引\n",
    "            cnt_argmax = np.argmax(uniq_cnts)\n",
    "            # print('uniqs : ',uniqs, 'cnts : ',uniq_cnts,'argmax:',cnt_argmax)\n",
    "            y_final_p[i] = uniqs[cnt_argmax]\n",
    "        return y_final_p, y_args\n",
    "    \n",
    "    def oob_score(self):\n",
    "        y_p , y_args = self.__oob_predict()\n",
    "        return np.sum(self.y_[y_args]==y_p) / len(y_args)\n",
    "    \n",
    "X,y = load_data()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "# sklearn学习器的训练\n",
    "sk_bgclf = BaggingClassifier(DecisionTreeClassifier(max_depth=5, splitter='random')).fit(X_train,y_train)\n",
    "sk_bagging_score = sk_bgclf.score(X_test,y_test)\n",
    "# 我的Simple Bagging 训练\n",
    "sb = SimpleBagging().fit(X_train,y_train)\n",
    "# 留出法\n",
    "print('my test score : ' , np.sum(sb.predict(X_test)==y_test) / len(y_test))\n",
    "print('sklearn bagging test score : ' , sk_bagging_score)\n",
    "\n",
    "print(\"-\"*100)\n",
    "# 自采样oob\n",
    "sk_bgclf = BaggingClassifier(DecisionTreeClassifier(max_depth=5, splitter='random'),oob_score=True).fit(X,y)\n",
    "#print('my oob score : ' , sb.oob_score())\n",
    "print('my oob score: ', sb.oob_score())\n",
    "print('sklearn bagging oob score' , sk_bgclf.oob_score_)\n",
    "\n",
    "#sb.oob_predict()\n",
    "#np.argpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "[1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.arange(0,11,1)\n",
    "mask = np.array([1,2,3])\n",
    "print(idxs)\n",
    "print(mask)\n",
    "#np.argwhere(mask)\n",
    "#idxs mask\n",
    "# Kanx\n",
    "idxs[mask] = -1\n",
    "idxs[idxs != -1]\n",
    "#idxs[np.isinmask]\n",
    "#idxs==mask\n",
    "#idxs[idxs==mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
